{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivalence relations\n",
    "## Evaluating a psychological phenomena on machine learning algorithms *\n",
    "\n",
    "* WORK IN PROGRESS\n",
    "\n",
    "This python script contains arrays on the task of evaluating relational derived response as a psychological phenomena related with complex behaviors such as cognition or language from a behaviorist viewpoint.\n",
    "\n",
    "The data are arrays of two list of bits where the first one is the encoded (sample) set of stimulus presented. The second is the (target) expected correct answer. \n",
    "\n",
    "# References\n",
    "\n",
    "Sidman, M. (2000). Equivalence relations and the reinforcement contingency. Journal of the Experimental Analysis of Behavior, 74(1), 127–146. http://doi.org/10.1901/jeab.2000.74-127\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1284788/\n",
    "\n",
    "Sidman, M. (2009). Equivalence Relations and Behavior: An Introductory Tutorial. The Analysis of Verbal Behavior, 25(1), 5–17.\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2779070/\n",
    "\n",
    "http://www.txaba.org/files/pdfs/Conference2017/StimulusEquivalence_Vaidya.pdf\n",
    "\n",
    "## also check:\n",
    "\n",
    "Testing Response-Stimulus Equivalence Relations Using Differential Responses as a Sample\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1592360/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#pybrain net\n",
    "import pybrain\n",
    "from pybrain.datasets import UnsupervisedDataSet, SupervisedDataSet\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.tools.validation import Validator\n",
    "\n",
    "#scikit-learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#datasets\n",
    "import train_datasets as tr_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_symmetry_a_b=[[[1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0],[1,0,0]],\n",
    "                    [[1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1],[1,0,0]],#\n",
    "                    [[1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0],[1,0,0]],\n",
    "                    [[1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1],[1,0,0]],\n",
    "                    [[1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,0],[1,0,0]],\n",
    "                    [[1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0],[1,0,0]],\n",
    "                    [[1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0],[0,1,0]],\n",
    "                    [[1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1],[0,1,0]],\n",
    "                    [[1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0],[0,1,0]],#\n",
    "                    [[1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1],[0,1,0]],\n",
    "                    [[1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0],[0,1,0]],\n",
    "                    [[1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0],[0,1,0]],\n",
    "                    [[1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0],[0,0,1]],#\n",
    "                    [[1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0],[0,0,1]],\n",
    "                    [[1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0],[0,0,1]],\n",
    "                    [[1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0],[0,0,1]],\n",
    "                    [[1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0],[0,0,1]],\n",
    "                    [[1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0],[0,0,1]],\n",
    "                    [[1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1],[0,0,0]], #A-CDE O_N\n",
    "                    [[1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0],[0,0,0]], #A-CED O_N\n",
    "                    [[1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1],[0,0,0]], #A-DCE O_N\n",
    "                    [[1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0],[0,0,0]], #A-DEC O_N\n",
    "                    [[1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0],[0,0,0]], #A-ECD O_N\n",
    "                    [[1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0],[0,0,0]] #A-EDC O_N\n",
    "                   ]\n",
    "#a_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dtrain = SupervisedDataSet(20,3) # define a dataset in pybrain\n",
    "[Dtrain.addSample(smpl[0],smpl[1]) for smpl in train_symmetry_a_b]\n",
    "print(Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validator =  Validator()\n",
    "net = buildNetwork(20,4,3, hiddenclass=pybrain.SigmoidLayer, outclass=pybrain.SigmoidLayer)\n",
    "T = BackpropTrainer(net, learningrate=0.01, momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in xrange(1500):\n",
    "    T.trainOnDataset(Dtrain, 1)\n",
    "    prediction = net.activateOnDataset(Dtrain)\n",
    "    scores.append(validator.MSE(prediction, Dtrain.getField('target')))\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#T.trainOnDataset(Dtrain, 1000)\n",
    "#print net.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[[1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1],[1,0,0]], #A-BCE #No entrenado\n",
    "#[[1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0],[0,1,0]], #A-DBC #No entrenado\n",
    "#[[1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0],[0,0,1]], #A-CDB #No entrenado\n",
    "#[1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1]# A-CDE #No entrenado\n",
    "#[1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1]# A-DCE #No entrenado\n",
    "#[0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0]#B-CAD #Test de simetría #No entrenado\n",
    "in_vals=[0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0]\n",
    "\n",
    "net.activate(in_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[net.activate(in_val[0]),in_val[1]] for in_val in train_symmetry_a_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_simetr_AB=[[[0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0],[1,0,0]],\n",
    "                [[0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1],[1,0,0]],\n",
    "                [[0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0],[1,0,0]],\n",
    "                [[0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1],[1,0,0]],\n",
    "                [[0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0],[1,0,0]],\n",
    "                [[0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0],[1,0,0]],\n",
    "                [[0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0],[0,1,0]],\n",
    "                [[0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1],[0,1,0]],\n",
    "                [[0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0],[0,1,0]],\n",
    "                [[0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1],[0,1,0]],\n",
    "                [[0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,1,0,0],[0,1,0]],\n",
    "                [[0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0],[0,1,0]],\n",
    "                [[0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0],[0,0,1]],\n",
    "                [[0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0],[0,0,1]],\n",
    "                [[0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0],[0,0,1]],\n",
    "                [[0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0],[0,0,1]],\n",
    "                [[0,1,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0],[0,0,1]],\n",
    "                [[0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0],[0,0,1]]\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_no_entren=[[[1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1],[1,0,0]], #A-BCE #No entrenado\n",
    "                [[1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0],[0,1,0]], #A-DBC #No entrenado\n",
    "                [[1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0],[0,0,1]], #A-CDB #No entrenado\n",
    "                #[[1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1],[0,0,0]], #A-CDE O_N\n",
    "                #[[1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0],[0,0,0]], #A-CED O_N\n",
    "                #[[1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1],[0,0,0]], #A-DCE O_N\n",
    "                [[1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0],[0,0,0]], #A-DEC O_N\n",
    "                [[1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0],[0,0,0]] #A-ECD O_N\n",
    "                #[[1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0],[0,0,0]], #A-EDC O_N\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[net.activate(in_val[0]),in_val[1]] for in_val in test_simetr_AB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_simmetry(train_symmetry_a_b,in_vec=20,out_vec=3, train_length=1500):\n",
    "    # train_symmetry_a_b = array de entrenamiento: valores entrada, valores de salida de la red\n",
    "    # test_simetr_AB = array de test: valores entrada, valores de salida de la red\n",
    "    # in_vec = longitud vector valores de entrada\n",
    "    # out_vec = longitud vector valores de salida\n",
    "    # train_length = Cantidad de ensayos de entrenamiento\n",
    "    Dtrain = SupervisedDataSet(in_vec,out_vec) # define a dataset in pybrain\n",
    "    [Dtrain.addSample(smpl[0],smpl[1]) for smpl in train_symmetry_a_b]\n",
    "    validator =  Validator()\n",
    "    net = buildNetwork(20,4,3, hiddenclass=pybrain.SigmoidLayer, outclass=pybrain.SigmoidLayer)\n",
    "    T = BackpropTrainer(net, learningrate=0.01, momentum=0.99)\n",
    "    scores = []\n",
    "    for i in xrange(train_length):\n",
    "        T.trainOnDataset(Dtrain, 1)\n",
    "        prediction = net.activateOnDataset(Dtrain)\n",
    "        scores.append(validator.MSE(prediction, Dtrain.getField('target')))\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.plot(scores)\n",
    "    print(\"**** Respuestas de entrenamiento\")\n",
    "    print(pd.DataFrame([[net.activate(in_val[0]),in_val[1]] for in_val in train_symmetry_a_b]))\n",
    "    print (\"Error ensayo final\", scores[500-1])\n",
    "    return net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_b_net=mlp_simmetry(train_symmetry_a_b,train_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[a_b_net.activate(in_val[0]),in_val[1]] for in_val in test_no_entren]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clasificadores de una capa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stims={\"A1\":[1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "       \"A2\":[0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "       \"A3\":[0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "       \"A4\":[0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "       \"B1\":[0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "       \"B2\":[0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "       \"B3\":[0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "       \"B4\":[0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "       \"C1\":[0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "       \"C2\":[0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "       \"C3\":[0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "       \"C4\":[0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1={\"labels\":[[i,j,k,l] for i in stims.keys() for j in stims.keys()for k in stims.keys()for l in stims.keys()],\n",
    "        \"values_x\":[np.array(i+j+k+l) for i in stims.values() for j in stims.values()for k in stims.values()for l in stims.values()],\n",
    "        \"values_y\":[np.bitwise_or(np.bitwise_or(np.bitwise_or(i,j),k),l) for i in stims.values() for j in stims.values()for k in stims.values()for l in stims.values()]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(test_1[\"values_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randrange(len(test_1[\"values_y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dat=random.randrange(len(test_1[\"values_y\"]))\n",
    "print(n_dat)\n",
    "print(test_1[\"labels\"][n_dat])\n",
    "print(test_1[\"values_x\"][n_dat])\n",
    "print(test_1[\"values_y\"][n_dat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=[[i,j,k,l] for i in stims.keys() for j in stims.keys()for k in stims.keys()for l in stims.keys()]\n",
    "values_x=[np.array(i+j+k+l) for i in stims.values() for j in stims.values()for k in stims.values()for l in stims.values()]\n",
    "test1_y=[list(np.bitwise_or(np.bitwise_or(np.bitwise_or(i,j),k),l)) for i in stims.values() for j in stims.values()for k in stims.values()for l in stims.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[[labels[i], values_x[i]]for i in xrange(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(values_x,test1_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)[source]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_1_view ():\n",
    "    n_dat=random.randrange(len(values_x))\n",
    "    print(n_dat)\n",
    "    print(values_x[n_dat,0:12])\n",
    "    print(values_x[n_dat,12:24])\n",
    "    print(values_x[n_dat,24:36])\n",
    "    print(values_x[n_dat,36:48])\n",
    "    print(test1_y[n_dat,:])\n",
    "    print(labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dat=random.randrange(len(test_1[\"values_y\"]))\n",
    "print(n_dat)\n",
    "print(test_1[\"labels\"][n_dat])\n",
    "print(test_1[\"values_x\"][n_dat])\n",
    "print(test_1[\"values_y\"][n_dat])\n",
    "clf.predict(np.array(test_1[\"values_x\"][n_dat]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot also the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # and testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reflexivity test dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stims={\"A1\":[1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "       \"A2\":[0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "       \"A3\":[0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "       \"A4\":[0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "       \"B1\":[0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "       \"B2\":[0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "       \"B3\":[0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "       \"B4\":[0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "       \"C1\":[0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "       \"C2\":[0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "       \"C3\":[0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "       \"C4\":[0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "      }\n",
    "\n",
    "options={\"O_1\":[1,0,0],\n",
    "         \"O_2\":[0,1,0],\n",
    "         \"O_3\":[0,0,1],\n",
    "         \"O_0\":[0,0,0],\n",
    "        }\n",
    "\n",
    "labels=np.array([[i,j,k,l] for i in stims.keys() for j in stims.keys()for k in stims.keys()for l in stims.keys()])\n",
    "values_x=np.array([np.array(i+j+k+l) for i in stims.values() for j in stims.values()for k in stims.values()for l in stims.values()])\n",
    "\n",
    "symmetry_A1_labels=labels[(labels[:,0]==\"A1\")&((labels[:,1]==\"A1\")|(labels[:,2]==\"A1\")|(labels[:,3]==\"A1\"))]\n",
    "symmetry_A1_values=values_x[(labels[:,0]==\"A1\")&((labels[:,1]==\"A1\")|(labels[:,2]==\"A1\")|(labels[:,3]==\"A1\"))]\n",
    "\n",
    "symmetry_A1_values=symmetry_A1_values[np.sum((symmetry_A1_labels[:,1:]==\"A1\")*1.0, axis=1)==1]\n",
    "symmetry_A1_labels=symmetry_A1_labels[np.sum((symmetry_A1_labels[:,1:]==\"A1\")*1.0, axis=1)==1]\n",
    "symmetry_A1_y=(symmetry_A1_labels[:,1:]==\"A1\")*1\n",
    "\n",
    "print(symmetry_A1_labels.shape)\n",
    "print(symmetry_A1_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dat=random.randrange(len(symmetry_A1_values))\n",
    "print(n_dat)\n",
    "print(symmetry_A1_values[n_dat,0:12])\n",
    "print(symmetry_A1_values[n_dat,12:24])\n",
    "print(symmetry_A1_values[n_dat,24:36])\n",
    "print(symmetry_A1_values[n_dat,36:48])\n",
    "print(symmetry_A1_y[n_dat,:])\n",
    "print(symmetry_A1_labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symm_labels=[]\n",
    "symm_values=[]\n",
    "symm_y=[]\n",
    "for lab in stims.keys(): \n",
    "    symmetry_labels=labels[(labels[:,0]==lab)&((labels[:,1]==lab)|(labels[:,2]==lab)|(labels[:,3]==lab))]\n",
    "    symmetry_values=values_x[(labels[:,0]==lab)&((labels[:,1]==lab)|(labels[:,2]==lab)|(labels[:,3]==lab))]\n",
    "\n",
    "    symmetry_values=symmetry_values[np.sum((symmetry_labels[:,1:]==lab)*1.0, axis=1)==1]\n",
    "    symmetry_labels=symmetry_labels[np.sum((symmetry_labels[:,1:]==lab)*1.0, axis=1)==1]\n",
    "    symmetry_y=(symmetry_labels[:,1:]==lab)*1\n",
    "    \n",
    "    [symm_labels.append(lbl) for lbl in symmetry_labels]\n",
    "    [symm_values.append(vle) for vle in symmetry_values]\n",
    "    [symm_y.append(vly) for vly in symmetry_y]\n",
    "symm_labels=np.array(symm_labels)\n",
    "symm_values=np.array(symm_values)\n",
    "symm_y=np.array(symm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (symm_labels.shape,\n",
    "       symm_values.shape,\n",
    "       symm_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dat=random.randrange(len(symm_values))\n",
    "print(n_dat)\n",
    "print(symm_values[n_dat,0:12])\n",
    "print(symm_values[n_dat,12:24])\n",
    "print(symm_values[n_dat,24:36])\n",
    "print(symm_values[n_dat,36:48])\n",
    "print(symm_y[n_dat,:])\n",
    "print(symm_labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[11,12,13,14],[25,26,27,28],[39,30,31,32]])\n",
    "print(A)\n",
    "B=A+30\n",
    "print(B)\n",
    "C=[]\n",
    "[C.append(Ai) for Ai in B]\n",
    "[C.append(Bi) for Bi in B]\n",
    "np.array(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symmetry_A1_labels\n",
    "labels[(labels[:,0]==\"A1\")&((labels[:,1]==\"A1\")|(labels[:,2]==\"A1\")|(labels[:,3]==\"A1\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(np.sum((symmetry_A1_labels[:,1:]==\"A1\")*1.0, axis=1)==1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_A1_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "stims={\"A1\":[1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "       \"A2\":[0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "       \"A3\":[0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "       \"A4\":[0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "       \"B1\":[0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "       \"B2\":[0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "       \"B3\":[0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "       \"B4\":[0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "       \"C1\":[0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "       \"C2\":[0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "       \"C3\":[0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "       \"C4\":[0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "      }\n",
    "\n",
    "options={\"O_1\":[1,0,0],\n",
    "         \"O_2\":[0,1,0],\n",
    "         \"O_3\":[0,0,1],\n",
    "         \"O_0\":[0,0,0],\n",
    "        }\n",
    "\n",
    "labels=np.array([[i,j,k,l] for i in stims.keys() for j in stims.keys()for k in stims.keys()for l in stims.keys()])\n",
    "values_x=np.array([np.array(i+j+k+l) for i in stims.values() for j in stims.values()for k in stims.values()for l in stims.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sample:\n",
    "    - must be the first element of the train pair.\n",
    "    - it has to be excluded on the comparator. \n",
    "    - ** does all the comparators must be the same mode as the target stimulus?**\n",
    "        - (Y) for experimental control\n",
    "        - (Y) avoid validation combinations in the train dataset\n",
    "        \n",
    "        \n",
    "- The target stimulus must be only once in the comparisons set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pairs=np.array([[\"A1\",\"B1\"],[\"B1\",\"C1\"],\n",
    "                      [\"A2\",\"B2\"],[\"B2\",\"C2\"],\n",
    "                      [\"A3\",\"B3\"],[\"B3\",\"C3\"],\n",
    "                      [\"A4\",\"B4\"],[\"B4\",\"C4\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-B B-C train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_train_x=np.any(\n",
    "    [\n",
    "        [((lbl[0]==pair[0])& #The sample is the first element of the pair\n",
    "          (lbl[1][0]==pair[1][0])& #The comparator 1 has the same mode (letter) of the second element of the pair\n",
    "          (lbl[2][0]==pair[1][0])& #The comparator 2 has the same mode (letter) of the second element of the pair\n",
    "          (lbl[3][0]==pair[1][0])& #The comparator 3 has the same mode (letter) of the second element of the pair\n",
    "          ((lbl[1]==pair[1])|(lbl[2]==pair[1])|(lbl[3]==pair[1]))&# any of the comparators is the second element of the pair\n",
    "          ((lbl[1]==pair[1])+(lbl[2]==pair[1])+(lbl[3]==pair[1])==1)# the second element of the pair is presented once in the comparators\n",
    "         ) for pair in train_pairs] for lbl in labels],# for any of the pairs on every label\n",
    "axis=1)\n",
    "\n",
    "train_values=values_x[filt_train_x]\n",
    "train_labels=  labels[filt_train_x]\n",
    "\n",
    "train_response=np.any(np.array([\n",
    "    [[\n",
    "        ((lbl[0]==pair[0])&(lbl[1]==pair[1])), #The sample is the first element of the pair and the first  comparator is the second element of the pair\n",
    "        ((lbl[0]==pair[0])&(lbl[2]==pair[1])), #The sample is the first element of the pair and the second comparator is the second element of the pair\n",
    "        ((lbl[0]==pair[0])&(lbl[3]==pair[1])) #The sample is the first element of the pair and the third  comparator is the second element of the pair\n",
    "    ] for pair in train_pairs] for lbl in train_labels]# for any of the pairs on every label\n",
    "), axis=1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_train():\n",
    "    n_dat=random.randrange(len(train_labels))\n",
    "    print(n_dat)\n",
    "    print(train_values[n_dat,0:12])\n",
    "    print(train_values[n_dat,12:24])\n",
    "    print(train_values[n_dat,24:36])\n",
    "    print(train_values[n_dat,36:48])\n",
    "    print(train_response[n_dat,:])\n",
    "    print(train_labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_stim=random.randrange(len(train_labels))\n",
    "n_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 1 0]\n",
      "['A2' 'B1' 'B2' 'B1']\n"
     ]
    }
   ],
   "source": [
    "view_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'symm_train_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-56e28eb0f972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymm_train_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_lbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcompar_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcompar_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'symm_train_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "pair=symm_train_pairs[0]\n",
    "n_lbl=random.randrange(len(labels))\n",
    "sample=0\n",
    "compar_1=1\n",
    "compar_2=2\n",
    "compar_3=3\n",
    "compar_mode_letter=pair[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['P1l1', 'P2l1', 'P3l1'],\n",
       "       ['P1l2', 'P2l2', 'P3l2'],\n",
       "       ['P1l3', 'P2l3', 'P3l3'],\n",
       "       ['P1l4', 'P2l4', 'P3l4']], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[(pair+lbl) for pair in [\"P1\",\"P2\",\"P3\"]] for lbl in [\"l1\",\"l2\",\"l3\",\"l4\"]])\n",
    "#print(symm_train_pairs)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[filt_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(filt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True+False+False==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symm_labels=[]\n",
    "symm_values=[]\n",
    "symm_y=[]\n",
    "for lab in stims.keys(): \n",
    "    symmetry_labels=labels[(labels[:,0]==lab)&((labels[:,1]==lab)|(labels[:,2]==lab)|(labels[:,3]==lab))]\n",
    "    symmetry_values=values_x[(labels[:,0]==lab)&((labels[:,1]==lab)|(labels[:,2]==lab)|(labels[:,3]==lab))]\n",
    "\n",
    "    symmetry_values=symmetry_values[np.sum((symmetry_labels[:,1:]==lab)*1.0, axis=1)==1]\n",
    "    symmetry_labels=symmetry_labels[np.sum((symmetry_labels[:,1:]==lab)*1.0, axis=1)==1]\n",
    "    symmetry_y=(symmetry_labels[:,1:]==lab)*1\n",
    "    \n",
    "    [symm_labels.append(lbl) for lbl in symmetry_labels]\n",
    "    [symm_values.append(vle) for vle in symmetry_values]\n",
    "    [symm_y.append(vly) for vly in symmetry_y]\n",
    "symm_labels=np.array(symm_labels)\n",
    "symm_values=np.array(symm_values)\n",
    "symm_y=np.array(symm_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Symmetry evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filt_symm_x=np.any(\n",
    "    [\n",
    "        [((lbl[0]==pair[1])& #The sample is the second element of the pair\n",
    "          (lbl[1][0]==pair[0][0])& #The comparator 1 has the same mode (letter) of the first element of the pair\n",
    "          (lbl[2][0]==pair[0][0])& #The comparator 2 has the same mode (letter) of the first element of the pair\n",
    "          (lbl[3][0]==pair[0][0])& #The comparator 3 has the same mode (letter) of the first element of the pair\n",
    "          ((lbl[1]==pair[0])|(lbl[2]==pair[0])|(lbl[3]==pair[0]))&# any of the comparators is the first element of the pair\n",
    "          ((lbl[1]==pair[0])+(lbl[2]==pair[0])+(lbl[3]==pair[0])==1)# the first element of the pair is presented once in the comparators\n",
    "         ) for pair in train_pairs] for lbl in labels],# for any of the pairs on every label\n",
    "axis=1)\n",
    "\n",
    "symmetry_values=values_x[filt_symm_x]\n",
    "symmetry_labels=  labels[filt_symm_x]\n",
    "\n",
    "symmetry_response=np.any(np.array([\n",
    "    [[\n",
    "        ((lbl[0]==pair[1])&(lbl[1]==pair[0])), #The sample is the second element of the pair and the first  comparator is the first element of the pair\n",
    "        ((lbl[0]==pair[1])&(lbl[2]==pair[0])), #The sample is the second element of the pair and the second comparator is the first element of the pair\n",
    "        ((lbl[0]==pair[1])&(lbl[3]==pair[0]))  #The sample is the second element of the pair and the third  comparator is the first element of the pair\n",
    "    ] for pair in train_pairs] for lbl in symmetry_labels]# for any of the pairs on every label\n",
    "), axis=1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_symmetry():\n",
    "    n_dat=random.randrange(len(symmetry_labels))\n",
    "    print(n_dat)\n",
    "    print(symmetry_values[n_dat,0:12])\n",
    "    print(symmetry_values[n_dat,12:24])\n",
    "    print(symmetry_values[n_dat,24:36])\n",
    "    print(symmetry_values[n_dat,36:48])\n",
    "    print(symmetry_response[n_dat,:])\n",
    "    print(symmetry_labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[1 0 0]\n",
      "['B2' 'A2' 'A3' 'A4']\n"
     ]
    }
   ],
   "source": [
    "view_symmetry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitivity and equivalence Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_pairs=np.array([[\"A1\",\"C1\"],\n",
    "                      [\"A2\",\"C2\"],\n",
    "                      [\"A3\",\"C3\"],\n",
    "                      [\"A4\",\"C4\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transitivity\n",
    "filt_transitivity_x=np.any(\n",
    "    [\n",
    "        [((lbl[0]==pair[0])& #The sample is the first element of the pair\n",
    "          (lbl[1][0]==pair[1][0])& #The comparator 1 has the same mode (letter) of the second element of the pair\n",
    "          (lbl[2][0]==pair[1][0])& #The comparator 2 has the same mode (letter) of the second element of the pair\n",
    "          (lbl[3][0]==pair[1][0])& #The comparator 3 has the same mode (letter) of the second element of the pair\n",
    "          ((lbl[1]==pair[1])|(lbl[2]==pair[1])|(lbl[3]==pair[1]))&# any of the comparators is the second element of the pair\n",
    "          ((lbl[1]==pair[1])+(lbl[2]==pair[1])+(lbl[3]==pair[1])==1)# the second element of the pair is presented once in the comparators\n",
    "         ) for pair in eval_pairs] for lbl in labels],# for any of the pairs on every label\n",
    "axis=1)\n",
    "\n",
    "transitivity_values=values_x[filt_transitivity_x]\n",
    "transitivity_labels=  labels[filt_transitivity_x]\n",
    "\n",
    "transitivity_response=np.any(np.array([\n",
    "    [[\n",
    "        ((lbl[0]==pair[0])&(lbl[1]==pair[1])), #The sample is the first element of the pair and the first  comparator is the second element of the pair\n",
    "        ((lbl[0]==pair[0])&(lbl[2]==pair[1])), #The sample is the first element of the pair and the second comparator is the second element of the pair\n",
    "        ((lbl[0]==pair[0])&(lbl[3]==pair[1])) #The sample is the first element of the pair and the third  comparator is the second element of the pair\n",
    "    ] for pair in eval_pairs] for lbl in transitivity_labels]# for any of the pairs on every label\n",
    "), axis=1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_transitivity():\n",
    "    n_dat=random.randrange(len(transitivity_labels))\n",
    "    print(n_dat)\n",
    "    print(transitivity_values[n_dat,0:12])\n",
    "    print(transitivity_values[n_dat,12:24])\n",
    "    print(transitivity_values[n_dat,24:36])\n",
    "    print(transitivity_values[n_dat,36:48])\n",
    "    print(transitivity_response[n_dat,:])\n",
    "    print(transitivity_labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[1 0 0]\n",
      "['A1' 'C1' 'C2' 'C4']\n"
     ]
    }
   ],
   "source": [
    "view_transitivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Equivalence\n",
    "filt_equivalence=np.any(\n",
    "    [\n",
    "        [((lbl[0]==pair[1])& #The sample is the second element of the pair\n",
    "          (lbl[1][0]==pair[0][0])& #The comparator 1 has the same mode (letter) of the first element of the pair\n",
    "          (lbl[2][0]==pair[0][0])& #The comparator 2 has the same mode (letter) of the first element of the pair\n",
    "          (lbl[3][0]==pair[0][0])& #The comparator 3 has the same mode (letter) of the first element of the pair\n",
    "          ((lbl[1]==pair[0])|(lbl[2]==pair[0])|(lbl[3]==pair[0]))&# any of the comparators is the first element of the pair\n",
    "          ((lbl[1]==pair[0])+(lbl[2]==pair[0])+(lbl[3]==pair[0])==1)# the first element of the pair is presented once in the comparators\n",
    "         ) for pair in eval_pairs] for lbl in labels],# for any of the pairs on every label\n",
    "axis=1)\n",
    "\n",
    "equivalence_values=values_x[filt_equivalence]\n",
    "equivalence_labels=  labels[filt_equivalence]\n",
    "\n",
    "equivalence_response=np.any(np.array([\n",
    "    [[\n",
    "        ((lbl[0]==pair[1])&(lbl[1]==pair[0])), #The sample is the second element of the pair and the first  comparator is the first element of the pair\n",
    "        ((lbl[0]==pair[1])&(lbl[2]==pair[0])), #The sample is the second element of the pair and the second comparator is the first element of the pair\n",
    "        ((lbl[0]==pair[1])&(lbl[3]==pair[0]))  #The sample is the second element of the pair and the third  comparator is the first element of the pair\n",
    "    ] for pair in eval_pairs] for lbl in equivalence_labels]# for any of the pairs on every label\n",
    "), axis=1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_equivalence():\n",
    "    n_dat=random.randrange(len(equivalence_labels))\n",
    "    print(n_dat)\n",
    "    print(equivalence_values[n_dat,0:12])\n",
    "    print(equivalence_values[n_dat,12:24])\n",
    "    print(equivalence_values[n_dat,24:36])\n",
    "    print(equivalence_values[n_dat,36:48])\n",
    "    print(equivalence_response[n_dat,:])\n",
    "    print(equivalence_labels[n_dat,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[0 1 0]\n",
      "['C1' 'A2' 'A1' 'A4']\n"
     ]
    }
   ],
   "source": [
    "view_equivalence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
