{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6944faa7-f52b-42c0-9dcb-d63377fff052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle\n",
    "from torch.nn import Transformer\n",
    "import pickle\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63841858-028f-4201-a36c-fb50a8c6a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#### Transformer Agent ########\n",
    "###############################\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size, decoder_mode=False):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.decoder_mode = decoder_mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        if self.decoder_mode:\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) #filter communication with past# comment this and you have an encoder block\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size, decoder_mode=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, decoder_mode=decoder_mode) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, decoder_mode=False):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, decoder_mode=decoder_mode)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_mode=False):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head, decoder_mode=decoder_mode) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4474d659-1da3-4fa0-bb43-70eeae5314a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(data):\n",
    "    # data must be train trials encoded and transformed in torch tensor\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    # data = train_tensor_encoded #if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data), (batch_size,)) \n",
    "    x = torch.stack([data[i,:block_size] for i in ix])\n",
    "    y = torch.stack([data[i,1:] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    # data = train_tensor_encoded# Modify for train several models\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch(data)\n",
    "        logits, loss = model(X, Y)\n",
    "        losses[k] = loss.item()\n",
    "    out[\"train\"] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1362f6-4549-4380-b6f2-bd0c38ee0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials_answers(tensor_encoded, model_trained, tell_me=True, tell_me_n_trials=1000):\n",
    "    # tensor_encoded: Pytorch tensor long(float64) type [sample, comp_1, comp_2, comp_3, comp_response] of all group trials\n",
    "    max_iters=tensor_encoded.shape[0]\n",
    "    response_stimulus=[]\n",
    "    for count, trial in enumerate(tensor_encoded[:,:-1]):\n",
    "        tokens_response=model_trained.generate(trial.reshape([1,-1]), max_new_tokens=1)[0].tolist()\n",
    "        response=decode(tokens_response)[-1]\n",
    "        response_stimulus.append(response)\n",
    "\n",
    "        if tell_me:\n",
    "            # tell me the progress every tell_me_n_trials\n",
    "            if count % tell_me_n_trials == 0 or count == max_iters - 1:\n",
    "                print(f\"{count} ({100.0*(count/max_iters):.2f}%) trials processed\")\n",
    "    return response_stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65679cac-7ae4-4eda-9c36-d4399c432182",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "  ####### FFN Agent ########\n",
    "###############################\n",
    "\n",
    "#### Agent train process function\n",
    "def train_agent(\n",
    "    train_trials_values,\n",
    "    train_trials_answers, \n",
    "    hidden_layer_units = 25000, \n",
    "    n_epochs = 5000,\n",
    "    batch_size=512\n",
    "):\n",
    "    # Randomize\n",
    "    np_inputs, np_labels= shuffle(\n",
    "        train_trials_values, \n",
    "        train_trials_answers)\n",
    "    \n",
    "    trial_input_length = np_inputs.shape[1]\n",
    "    trial_output_length = np_labels.shape[1]\n",
    "    \n",
    "    # Define the network architecture\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(trial_input_length, hidden_layer_units)\n",
    "            # self.fc2 = nn.Linear(hidden_layer_units, hidden_layer_units)\n",
    "            self.fc3 = nn.Linear(hidden_layer_units, trial_output_length)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            # x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)  # identity activation function\n",
    "            return x\n",
    "    \n",
    "    # Instantiate the network, the optimizer and the loss function\n",
    "    net = Net().to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    \n",
    "    # Convert the new input data to a PyTorch tensor # Evaluation of train\n",
    "    train_inputs = torch.from_numpy(train_trials_values).float().to(device)\n",
    "    train_labels = torch.from_numpy(train_trials_answers).float().to(device)\n",
    "    \n",
    "    # Convert numpy arrays to PyTorch tensors # Inputs to train phase\n",
    "    inputs = torch.from_numpy(np_inputs).float().to(device)\n",
    "    labels = torch.from_numpy(np_labels).float().to(device)\n",
    "    \n",
    "    # Create a dataset and a data loader\n",
    "    dataset = TensorDataset(inputs, labels)\n",
    "    trainloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    epochs_errors_list = []\n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs): # number of epochs\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs).to(device)\n",
    "            loss = torch.sqrt(criterion(outputs, labels))  # RMSE\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss = loss.item()\n",
    "            # if (i == (train_labels.shape[0]//trainloader.batch_size)) & ((epoch % 50) == 0):  # print every 512 mini-batches\n",
    "            #     print('epoch %5d  batch loss: %.4f' %\n",
    "            #           (epoch, running_loss))\n",
    "            #     running_loss = 0.0\n",
    "        \n",
    "        # Make predictions on the new data \n",
    "        with torch.no_grad():\n",
    "            new_predictions = net(train_inputs) ### PERFORMANCE BOTTLENECK\n",
    "        dat_RMSE = torch.sqrt(((torch.pow((new_predictions - train_labels), 2)).sum()) / new_predictions.shape[0])\n",
    "        epochs_errors_list.append(dat_RMSE.item())\n",
    "        \n",
    "        if (epoch % int(n_epochs/20) == 0) or (dat_RMSE<.001) :\n",
    "            clear_output(wait=True)\n",
    "            plt.plot(range(len(epochs_errors_list)), \n",
    "                     epochs_errors_list, \n",
    "                     alpha = .8,\n",
    "                     linewidth=.5\n",
    "                    )\n",
    "            plt.axhline(y=.0025, linestyle='--', c=sns.color_palette().as_hex()[2])\n",
    "            plt.axhline(y=.001, linestyle='--', c=sns.color_palette().as_hex()[1])\n",
    "            plt.title (\"Error\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"RMSE\")\n",
    "            plt.yscale('log')\n",
    "            plt.show()\n",
    "                    \n",
    "        if dat_RMSE<.001: #.0005\n",
    "            print(\"The RMSE of the train data evaluation falls below the criteria.\")\n",
    "            break\n",
    "    print('Finished Training', str(dat_RMSE), str(epoch+1), \"epochs\")\n",
    "    \n",
    "    return net\n",
    "\n",
    "def get_evaluation_responses(agent, test_trials_values, test_trials_answers, batch_size=512):\n",
    "    # Convert the new input data to PyTorch tensors\n",
    "    new_inputs = torch.from_numpy(test_trials_values).float().to(device)\n",
    "    new_labels = torch.from_numpy(test_trials_answers).float().to(device)\n",
    "\n",
    "    # Create a dataset and data loader\n",
    "    dataset = TensorDataset(new_inputs, new_labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    # Make predictions on the new data in batches\n",
    "    with torch.no_grad():\n",
    "        test_logits_list = []\n",
    "        for inputs, labels in dataloader:\n",
    "            test_logits = agent(inputs)\n",
    "            test_logits_list.append(test_logits)\n",
    "\n",
    "    # Concatenate the logits from all batches\n",
    "    test_logits = torch.cat(test_logits_list, dim=0)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    dat_RMSE = torch.sqrt(((torch.pow((test_logits - new_labels), 2)).sum()) / test_logits.shape[0])\n",
    "    print(\"logits RMSE:\", dat_RMSE.item())\n",
    "\n",
    "    # Calculate softmax probabilities and response\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    test_probabilities = softmax(test_logits)\n",
    "    test_response = torch.argmax(test_probabilities, dim=1)\n",
    "\n",
    "    # Convert the predictions to a numpy array\n",
    "    logits_np = test_logits.cpu().numpy()\n",
    "    # probabilities_np = test_probabilities.cpu().numpy()\n",
    "    response_np = test_response.cpu().numpy()\n",
    "\n",
    "    return logits_np, response_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b606aec-b3be-4e9a-8c74-4b979d2d70a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x1d85c237020>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.cuda.device(i) for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fbf65fe-07e4-4e5a-ad24-accc8df182bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885bdd12-1cf6-4bb3-a24d-24736ab4e53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../utils/trials_v04a.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd7cf2f-4c3c-49eb-967d-a47852c3013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#############  Experiment Parameters\n",
    "members_number = 6#5#5\n",
    "classes_number = 4#3#7\n",
    "same_label_trials = True\n",
    "############################################# \n",
    "\n",
    "filter_condition = \"\"\n",
    "if same_label_trials:\n",
    "    filter_condition = \"filt\"\n",
    "else:\n",
    "    filter_condition = \"unfilt\"\n",
    "\n",
    "experiment_name = f\"agents3_v04_m{members_number}_c{classes_number}_{filter_condition}\"\n",
    "folder_path = experiment_name+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c947e3-4181-4819-bbfa-ea2424afe55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_stim, class_stim, stimuli_set, dummy_set = get_stimuli_list(members_n = members_number, classes_n = classes_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f7d67d-8cde-4a08-b419-cc5c99124595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LS_select_reject',\n",
       " 'LS_select_only',\n",
       " 'LS_reject_only',\n",
       " 'OTM_select_reject',\n",
       " 'OTM_select_only',\n",
       " 'OTM_reject_only',\n",
       " 'MTO_select_reject',\n",
       " 'MTO_select_only',\n",
       " 'MTO_reject_only']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols_dict = {f\"{ts}_{relation}\": {'train_structure': ts, 'relation_type': relation} \n",
    "                  for ts in [\"LS\", \"OTM\", \"MTO\"] for relation in [\n",
    "                      'select_reject',\n",
    "                      'select_only', \n",
    "                      'reject_only', \n",
    "                  ]}\n",
    "list(protocols_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a72d3e-7ac5-4590-aa96-22965e895564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of the train data evaluation falls below the criteria.\n",
      "Finished Training tensor(0.0009, device='cuda:0') 10865 epochs\n",
      "GPT agent\n",
      "0 (0.00%) trials processed\n",
      "259 (9.99%) trials processed\n",
      "518 (19.98%) trials processed\n",
      "777 (29.98%) trials processed\n",
      "1036 (39.97%) trials processed\n",
      "1295 (49.96%) trials processed\n",
      "1554 (59.95%) trials processed\n",
      "1813 (69.95%) trials processed\n",
      "2072 (79.94%) trials processed\n",
      "2331 (89.93%) trials processed\n",
      "2590 (99.92%) trials processed\n",
      "2591 (99.96%) trials processed\n",
      "BERT agent\n",
      "0 (0.00%) trials processed\n",
      "259 (9.99%) trials processed\n",
      "518 (19.98%) trials processed\n",
      "777 (29.98%) trials processed\n",
      "1036 (39.97%) trials processed\n",
      "1295 (49.96%) trials processed\n",
      "1554 (59.95%) trials processed\n",
      "1813 (69.95%) trials processed\n",
      "2072 (79.94%) trials processed\n",
      "2331 (89.93%) trials processed\n",
      "2590 (99.92%) trials processed\n",
      "2591 (99.96%) trials processed\n",
      "logits RMSE: 1.2458776235580444\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "#############  LOOP PROTOCOLS\n",
    "############################################# \n",
    "protocol_names=list(protocols_dict.keys())\n",
    "\n",
    "for prt_nm in protocol_names:\n",
    "    ##12\n",
    "    print(prt_nm)\n",
    "    protocol = protocols_dict[prt_nm]\n",
    "    member_pairs_df = create_pair_members(members_stim, train_structure = protocol[\"train_structure\"])\n",
    "    experimental_pairs = create_pairs_classes(member_pairs_df, class_stim)\n",
    "    ##13\n",
    "    baseline_train_trials_info = create_trials(\n",
    "        subset_to_trials = \"baseline\", \n",
    "        pairs_dataset_df = experimental_pairs, \n",
    "        stimuli_list = stimuli_set, \n",
    "        dummy_list = dummy_set, \n",
    "        relation_type = protocol['relation_type'],\n",
    "        same_label_filter = same_label_trials\n",
    "    )\n",
    "    \n",
    "    reflexivity_trials_info = create_trials(\n",
    "        subset_to_trials = \"reflexivity\", \n",
    "        pairs_dataset_df = experimental_pairs, \n",
    "        stimuli_list = stimuli_set, \n",
    "        dummy_list = dummy_set, \n",
    "        relation_type = \"select_reject\",\n",
    "        same_label_filter = same_label_trials\n",
    "    )\n",
    "    \n",
    "    symmetry_trials_info = create_trials(\n",
    "        subset_to_trials = \"symmetry\", \n",
    "        pairs_dataset_df = experimental_pairs, \n",
    "        stimuli_list = stimuli_set, \n",
    "        dummy_list = dummy_set, \n",
    "        relation_type = \"select_reject\",\n",
    "        same_label_filter = same_label_trials\n",
    "    )\n",
    "    \n",
    "    transitivity_trials_info = create_trials(\n",
    "        subset_to_trials = \"transitivity\", \n",
    "        pairs_dataset_df = experimental_pairs, \n",
    "        stimuli_list = stimuli_set, \n",
    "        dummy_list = dummy_set, \n",
    "        relation_type = \"select_reject\",\n",
    "        same_label_filter = same_label_trials\n",
    "    )\n",
    "    \n",
    "    ##14\n",
    "    #############################################\n",
    "    ###   train Agents\n",
    "    \n",
    "    ##15\n",
    "    trials_info_columns=[\"st_sample\",\"st_comp1\",\"st_comp2\",\"st_comp3\",\"option_answer\"]#\"st_comparison\"\n",
    "    train_trials_corpus_df=baseline_train_trials_info[trials_info_columns]\n",
    "    ##16\n",
    "    options_list = list(train_trials_corpus_df.option_answer.unique())\n",
    "    ##17\n",
    "    tokens_list = stimuli_set+dummy_set+options_list\n",
    "    token_to_index = {token: index for index, token in enumerate(tokens_list)}\n",
    "    ##18\n",
    "    encoded_training_data = np.array([[token_to_index[token] for token in sequence] for sequence in np.array(train_trials_corpus_df)])\n",
    "    train_tensor_encoded=torch.from_numpy(encoded_training_data).int().to(device)\n",
    "    train_tensor_encoded=train_tensor_encoded.to(torch.long)\n",
    "    ##19\n",
    "    # set seed for reproductibility\n",
    "    torch.manual_seed(183)\n",
    "    \n",
    "    # hyperparameters\n",
    "    batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "    block_size = 4 # what is the maximum context length for predictions?\n",
    "    max_iters = 10000\n",
    "    eval_interval = 500\n",
    "    learning_rate = 3e-4\n",
    "    eval_iters = 200\n",
    "    \n",
    "    n_embd = 384\n",
    "    n_head = 6\n",
    "    n_layer = 6\n",
    "    dropout = 0.2\n",
    "    ##20\n",
    "    # here are all the unique characters that occur in this text\n",
    "    chars = tokens_list\n",
    "    vocab_size = len(chars)\n",
    "    # create a mapping from characters to integers\n",
    "    stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "    itos = { i:ch for i,ch in enumerate(chars) }\n",
    "    encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "    decode = lambda l: [itos[i] for i in l]#lambda l: ','.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "    ##21\n",
    "    data=train_tensor_encoded\n",
    "    ##22\n",
    "    GPT_instance = TransformerModel(decoder_mode=True)\n",
    "    GPT_model = GPT_instance.to(device)\n",
    "    # print the number of parameters in the model\n",
    "    print(sum(p.numel() for p in GPT_model.parameters())/1e6, 'M parameters')\n",
    "    \n",
    "    # create a PyTorch optimizer\n",
    "    GPT_optimizer = torch.optim.AdamW(GPT_instance.parameters(), lr=learning_rate)\n",
    "    model = GPT_model\n",
    "    \n",
    "    for iter in range(max_iters):\n",
    "    \n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss()\n",
    "            # print(losses)\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}\")\n",
    "    \n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch(data)\n",
    "    \n",
    "        # evaluate the loss\n",
    "        logits, loss = GPT_instance(xb, yb)\n",
    "        GPT_optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        GPT_optimizer.step()\n",
    "    ##23\n",
    "    BERT_instance = TransformerModel(decoder_mode=False)\n",
    "    BERT_model = BERT_instance.to(device)\n",
    "    # print the number of parameters in the model\n",
    "    print(sum(p.numel() for p in BERT_model.parameters())/1e6, 'M parameters')\n",
    "    \n",
    "    \n",
    "    # create a PyTorch optimizer\n",
    "    BERT_optimizer = torch.optim.AdamW(BERT_instance.parameters(), lr=learning_rate)\n",
    "    model = BERT_model\n",
    "    \n",
    "    for iter in range(max_iters):\n",
    "    \n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss()\n",
    "            # print(losses)\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}\")\n",
    "    \n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch(data)\n",
    "    \n",
    "        # evaluate the loss\n",
    "        logits, loss = BERT_instance(xb, yb)\n",
    "        BERT_optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        BERT_optimizer.step()\n",
    "    ##24\n",
    "    \n",
    "    ##25\n",
    "    ##### Encode Trials\n",
    "    # This encoding can be used in a loop for validate stability across several experiments avoiding learning related to feature encoding positioning. \n",
    "    stimuli_dict_encoded = encode_stims (stimuli_set, dummy_set)\n",
    "    ##26\n",
    "    baseline_train_trials, baseline_train_answers = process_trial_values(\n",
    "        baseline_train_trials_info, \n",
    "        stimuli_dict_encoded)\n",
    "    ##27\n",
    "    trained_agent = train_agent(\n",
    "        train_trials_values = baseline_train_trials, \n",
    "        train_trials_answers = baseline_train_answers,\n",
    "        hidden_layer_units = 50000, \n",
    "        n_epochs = 50000,\n",
    "    )\n",
    "    ##28\n",
    "    \n",
    "    ##29\n",
    "    full_trials=pd.concat([\n",
    "        baseline_train_trials_info,\n",
    "        reflexivity_trials_info,\n",
    "        symmetry_trials_info,\n",
    "        transitivity_trials_info,\n",
    "    ],ignore_index=True)\n",
    "    \n",
    "    ##30\n",
    "    full_trials_corpus_df=full_trials[trials_info_columns]\n",
    "    ##31\n",
    "    # encode corpus in positional tokens\n",
    "    encoded_full_trials_data = np.array([[token_to_index[token] for token in sequence] for sequence in np.array(full_trials_corpus_df)])\n",
    "    full_trials_tensor_encoded=torch.from_numpy(encoded_full_trials_data).int().to(device)\n",
    "    full_trials_tensor_encoded=full_trials_tensor_encoded.to(torch.long)\n",
    "    ##32\n",
    "    n_full_trials_report=int(full_trials_tensor_encoded.shape[0]/10)\n",
    "    ##33\n",
    "    print(\"GPT agent\")\n",
    "    trials_responses_GPT=get_trials_answers(full_trials_tensor_encoded, GPT_model, tell_me_n_trials=n_full_trials_report)\n",
    "    print(\"BERT agent\")\n",
    "    trials_responses_BERT=get_trials_answers(full_trials_tensor_encoded, BERT_model, tell_me_n_trials=n_full_trials_report)\n",
    "    ##34\n",
    "    # Evaluate FFN\n",
    "    full_trials_values, full_trials_answers = process_trial_values(\n",
    "        full_trials, \n",
    "        stimuli_dict_encoded)\n",
    "    \n",
    "    full_trials_logits, full_trials_response = get_evaluation_responses (\n",
    "        agent = trained_agent, \n",
    "        test_trials_values = full_trials_values, \n",
    "        test_trials_answers = full_trials_answers\n",
    "    )\n",
    "    \n",
    "    trials_responses_FFN = [\"O_\"+str(rsp+1) for rsp in full_trials_response]\n",
    "    ##35\n",
    "    full_trials[\"GPT_response\"]=trials_responses_GPT\n",
    "    full_trials[\"BERT_response\"]=trials_responses_BERT\n",
    "    full_trials[\"FFN_response\"]=trials_responses_FFN\n",
    "    ##36\n",
    "    full_trials['sample_member']=[stim[0] for stim in full_trials.st_sample]\n",
    "    full_trials['comparison_member']=[stim[0] for stim in full_trials.st_comparison]\n",
    "    \n",
    "    full_trials[\"GPT_response_score\"] = (full_trials[\"GPT_response\"]==full_trials[\"option_answer\"])*1\n",
    "    full_trials[\"BERT_response_score\"] = (full_trials[\"BERT_response\"]==full_trials[\"option_answer\"])*1\n",
    "    full_trials[\"FFN_response_score\"] = (full_trials[\"FFN_response\"]==full_trials[\"option_answer\"])*1\n",
    "    \n",
    "    ##37\n",
    "    full_trials.to_pickle(\"salidas/\"+folder_path+prt_nm+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e1cc27-303c-450a-acdf-0146b36f6d0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2635050600.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    STOP!\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494746d-d35d-47aa-90b2-74e20df6e4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0a782-0593-4f41-be6e-e91b127a7a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5e77f-4dee-46a9-9926-93c9ba0ae31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prt_nm = 1\n",
    "same_label_trials = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646268d7-d60e-4f06-b33c-29949918cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_names=list(protocols_dict.keys())\n",
    "print(protocol_names[prt_nm])\n",
    "protocol = protocols_dict[protocol_names[prt_nm]]\n",
    "member_pairs_df = create_pair_members(members_stim, train_structure = protocol[\"train_structure\"])\n",
    "experimental_pairs = create_pairs_classes(member_pairs_df, class_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b89aa3-a452-4129-b360-491b02bac8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_trials_info = create_trials(\n",
    "    subset_to_trials = \"baseline\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = protocol['relation_type'],\n",
    "    same_label_filter = same_label_trials\n",
    ")\n",
    "\n",
    "reflexivity_trials_info = create_trials(\n",
    "    subset_to_trials = \"reflexivity\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = \"select_reject\",\n",
    "    same_label_filter = same_label_trials\n",
    ")\n",
    "\n",
    "symmetry_trials_info = create_trials(\n",
    "    subset_to_trials = \"symmetry\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = \"select_reject\",\n",
    "    same_label_filter = same_label_trials\n",
    ")\n",
    "\n",
    "transitivity_trials_info = create_trials(\n",
    "    subset_to_trials = \"transitivity\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = \"select_reject\",\n",
    "    same_label_filter = same_label_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec2620-3802-4972-8a2b-71ff1556f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "###   train Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8f5a3-f263-4fd8-9311-58c7713d656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_info_columns=[\"st_sample\",\"st_comp1\",\"st_comp2\",\"st_comp3\",\"option_answer\"]#\"st_comparison\"\n",
    "train_trials_corpus_df=baseline_train_trials_info[trials_info_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef2153-df0d-48a9-ba25-defc09132e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_list = list(train_trials_corpus_df.option_answer.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13313eff-8708-4f42-a4f7-1b2314408570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = stimuli_set+dummy_set+options_list\n",
    "token_to_index = {token: index for index, token in enumerate(tokens_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bd7c5-73e5-43be-9b49-e523d11da88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_training_data = np.array([[token_to_index[token] for token in sequence] for sequence in np.array(train_trials_corpus_df)])\n",
    "train_tensor_encoded=torch.from_numpy(encoded_training_data).int().to(device)\n",
    "train_tensor_encoded=train_tensor_encoded.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e089c2e-445f-4698-a32b-915ec47115c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seed for reproductibility\n",
    "torch.manual_seed(183)\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 4 # what is the maximum context length for predictions?\n",
    "max_iters = 10000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 200\n",
    "\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89627c16-638c-4a59-8005-70ef1293e318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = tokens_list\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: [itos[i] for i in l]#lambda l: ','.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167a7c5-0a07-40de-a739-6edb024b490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train_tensor_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913876ed-99a5-4108-bfd0-338b1a2e413b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPT_instance = TransformerModel(decoder_mode=True)\n",
    "GPT_model = GPT_instance.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in GPT_model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "GPT_optimizer = torch.optim.AdamW(GPT_instance.parameters(), lr=learning_rate)\n",
    "model = GPT_model\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        # print(losses)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(data)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = GPT_instance(xb, yb)\n",
    "    GPT_optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    GPT_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175d267-c717-46ae-838d-4c7e4f3ab3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_instance = TransformerModel(decoder_mode=False)\n",
    "BERT_model = BERT_instance.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in BERT_model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "BERT_optimizer = torch.optim.AdamW(BERT_instance.parameters(), lr=learning_rate)\n",
    "model = BERT_model\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        # print(losses)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(data)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = BERT_instance(xb, yb)\n",
    "    BERT_optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    BERT_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc608ff-fa72-43e3-afdc-b95316f9364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac9aa4-ad5e-4686-b16c-122ce632e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Encode Trials\n",
    "# This encoding can be used in a loop for validate stability across several experiments avoiding learning related to feature encoding positioning. \n",
    "stimuli_dict_encoded = encode_stims (stimuli_set, dummy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7581cb-6a18-4cd3-b34e-2c562f7a9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_trials, baseline_train_answers = process_trial_values(\n",
    "    baseline_train_trials_info, \n",
    "    stimuli_dict_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355ca0e-c92f-46bc-ba5f-cf65878ce1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_agent = train_agent(\n",
    "    train_trials_values = baseline_train_trials, \n",
    "    train_trials_answers = baseline_train_answers,\n",
    "    hidden_layer_units = 50000, \n",
    "    n_epochs = 50000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fb13a-843e-4f18-84a0-be7e50720b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### evaluate test trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329855d-ca36-4568-98bf-953519892e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_trials=pd.concat([\n",
    "    baseline_train_trials_info,\n",
    "    reflexivity_trials_info,\n",
    "    symmetry_trials_info,\n",
    "    transitivity_trials_info,\n",
    "],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80706d-6952-487f-aa03-9f298d07d470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_trials_corpus_df=full_trials[trials_info_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c2e68-f160-43d4-b56d-381ae1744601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode corpus in positional tokens\n",
    "encoded_full_trials_data = np.array([[token_to_index[token] for token in sequence] for sequence in np.array(full_trials_corpus_df)])\n",
    "full_trials_tensor_encoded=torch.from_numpy(encoded_full_trials_data).int().to(device)\n",
    "full_trials_tensor_encoded=full_trials_tensor_encoded.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ffdc8-eb4e-49da-8289-254b0a4bddfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_full_trials_report=int(full_trials_tensor_encoded.shape[0]/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5b373-2a56-4eae-ad04-18c6572e533d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"GPT agent\")\n",
    "trials_responses_GPT=get_trials_answers(full_trials_tensor_encoded, GPT_model, tell_me_n_trials=n_full_trials_report)\n",
    "print(\"BERT agent\")\n",
    "trials_responses_BERT=get_trials_answers(full_trials_tensor_encoded, BERT_model, tell_me_n_trials=n_full_trials_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa7924-1c57-444e-bb77-979244986498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate FFN\n",
    "full_trials_values, full_trials_answers = process_trial_values(\n",
    "    full_trials, \n",
    "    stimuli_dict_encoded)\n",
    "\n",
    "full_trials_logits, full_trials_response = get_evaluation_responses (\n",
    "    agent = trained_agent, \n",
    "    test_trials_values = full_trials_values, \n",
    "    test_trials_answers = full_trials_answers\n",
    ")\n",
    "\n",
    "trials_responses_FFN = [\"O_\"+str(rsp+1) for rsp in full_trials_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97070760-2fd7-4407-8880-a56dfeda7da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trials[\"GPT_response\"]=trials_responses_GPT\n",
    "full_trials[\"BERT_response\"]=trials_responses_BERT\n",
    "full_trials[\"FFN_response\"]=trials_responses_FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fcbe32-5dcd-489a-9e86-06553b0ea694",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trials['sample_member']=[stim[0] for stim in full_trials.st_sample]\n",
    "full_trials['comparison_member']=[stim[0] for stim in full_trials.st_comparison]\n",
    "\n",
    "full_trials[\"GPT_response_score\"] = (full_trials[\"GPT_response\"]==full_trials[\"option_answer\"])*1\n",
    "full_trials[\"BERT_response_score\"] = (full_trials[\"BERT_response\"]==full_trials[\"option_answer\"])*1\n",
    "full_trials[\"FFN_response_score\"] = (full_trials[\"FFN_response\"]==full_trials[\"option_answer\"])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e99a3f-6e39-4f07-a3a8-e62301818e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_trials.to_pickle(\"salidas/\"+protocol_names[prt_nm]+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e3bba-f4e9-4493-a6b7-2538cf1a91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "########### Explore trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5eed88-0261-41cb-8872-0f658f5d33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_number = 7#5#\n",
    "classes_number = 5#3#\n",
    "\n",
    "members_stim, class_stim, stimuli_set, dummy_set = get_stimuli_list(members_n = members_number, classes_n = classes_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf7792-21a8-4c7b-ab44-cffc0a3874dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prt_nm = 1\n",
    "same_label_trials = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c9031-bf90-4157-81a7-efbeac0458c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_names=list(protocols_dict.keys())\n",
    "print(protocol_names[prt_nm])\n",
    "protocol = protocols_dict[protocol_names[prt_nm]]\n",
    "member_pairs_df = create_pair_members(members_stim, train_structure = protocol[\"train_structure\"])\n",
    "experimental_pairs = create_pairs_classes(member_pairs_df, class_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822e035-b60d-4079-a68d-c70802ff804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_trials_info = create_trials(\n",
    "    subset_to_trials = \"baseline\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = protocol['relation_type'],\n",
    "    same_label_filter = same_label_trials\n",
    ")\n",
    "\n",
    "reflexivity_trials_info = create_trials(\n",
    "    subset_to_trials = \"reflexivity\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = \"select_reject\",\n",
    "    same_label_filter = same_label_trials\n",
    ")\n",
    "\n",
    "symmetry_trials_info = create_trials(\n",
    "    subset_to_trials = \"symmetry\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = \"select_reject\",\n",
    "    same_label_filter = same_label_trials\n",
    ")\n",
    "\n",
    "transitivity_trials_info = create_trials(\n",
    "    subset_to_trials = \"transitivity\", \n",
    "    pairs_dataset_df = experimental_pairs, \n",
    "    stimuli_list = stimuli_set, \n",
    "    dummy_list = dummy_set, \n",
    "    relation_type = \"select_reject\",\n",
    "    same_label_filter = same_label_trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a31c7e-a3f9-4e4c-9988-c628497ef53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_trials=pd.concat([\n",
    "    baseline_train_trials_info,\n",
    "    reflexivity_trials_info,\n",
    "    symmetry_trials_info,\n",
    "    transitivity_trials_info,\n",
    "],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441cd93a-1a26-4a2f-8d3f-0c450d4d7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_trials.to_csv(\"same_label_\"+protocol_names[prt_nm]+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
