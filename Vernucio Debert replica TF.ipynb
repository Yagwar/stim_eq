{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Simulation of Equivalence Class Formation Using the go/no-go Procedure with Compound Stimuli\n",
    "\n",
    "### Abstract\n",
    "Research about equivalence has commonly utilized human participants as experimental subjects. More recently, computational models have been capable of reproducing performances observed in experiments with humans. The computational model often utilized is called RELNET, and it simulates training and testing trials of conditional relations using the matching-to-sample procedure (MTS). The differentiation between sample stimulus and comparison stimuli, indispensable in MTS, implies operational difficulties for simulations. For this reason, new studies seek to utilize alternative procedures to MTS, which do not differentiate the functions of the antecedent stimuli. This work evaluated the possibility of developing a new computational model to simulate equivalence class formation using the go/no-go procedure with compound stimuli. In Experiment 1, artificial neural networks were utilized to simulate training of the AB and BC relations as well as the testing of the AC relation. The results showed that four out of six runs demonstrated equivalence class formation. Experiment 2 evaluated whether the additional class training performed in Experiment 1, which was analogous to the simulation of pre-experimental experience of human participants, would be essential for simulating the establishment of equivalence classes. It was found that it was not possible to simulate equivalence class formation without the additional class training. Altogether, the experiments show that it is possible to simulate equivalence class formation using the go/no-go procedure with compound stimuli and that it is necessary to conduct additional class training. The model developed is, therefore, an alternative to RELNET for the study of equivalence relations using computational simulations.\n",
    "\n",
    "[article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4960284/pdf/40732_2016_Article_184.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow replica\n",
    "\n",
    "[XOR example (simplest)](https://medium.com/@jaschaephraim/elementary-neural-networks-with-tensorflow-c2593ad3d60b)\n",
    "[MNIST example](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/neural_network_raw.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1_X=[\n",
    "    [0.,0.,0.,1.,0.,1.,0.,0.,0.],# 0 0 0 1 0 1 0 0 0 \n",
    "    [0.,1.,0.,0.,0.,1.,0.,0.,0.],# 0 1 0 0 0 1 0 0 0\n",
    "    [0.,1.,0.,1.,0.,0.,0.,0.,0.],# 0 1 0 1 0 0 0 0 0\n",
    "    [1.,0.,0.,0.,0.,0.,0.,1.,0.],# 1 0 0 0 0 0 0 1 0  \n",
    "    [1.,0.,1.,0.,0.,0.,0.,0.,0.],# 1 0 1 0 0 0 0 0 0 \n",
    "    [0.,0.,0.,0.,1.,0.,0.,1.,0.],# 0 0 0 0 1 0 0 1 0 \n",
    "    [0.,0.,0.,0.,0.,0.,1.,1.,0.],# 0 0 0 0 0 0 1 1 0 \n",
    "    [0.,0.,1.,0.,0.,0.,0.,0.,1.],# 0 0 1 0 0 0 0 0 1\n",
    "    [0.,0.,0.,0.,0.,0.,0.,1.,1.],# 0 0 0 0 0 0 0 1 1 \n",
    "    [0.,0.,1.,0.,0.,0.,1.,0.,0.],# 0 0 1 0 0 0 1 0 0\n",
    "    [0.,0.,1.,0.,1.,0.,0.,0.,0.] # 0 0 1 0 1 0 0 0 0 \n",
    "]\n",
    "\n",
    "train_1_y=[1,1,1,1,0,1,0,1,0,1,0] \n",
    "\n",
    "test_1_X=[\n",
    "    [1.,0.,0.,0.,1.,0.,0.,0.,0.],\n",
    "    [1.,0.,0.,0.,0.,0.,1.,0.,0.],\n",
    "    [0.,0.,0.,0.,0.,0.,1.,0.,1.],\n",
    "    [0.,0.,0.,0.,1.,0.,0.,0.,1.]\n",
    "]\n",
    "\n",
    "test_1_y=[1,0,1,0]\n",
    "\n",
    "train_2_X=[\n",
    "    [1.,0.,0.,0.,1.,0.],# 1 0 0 0 1 0\n",
    "    [1.,1.,0.,0.,0.,0.],# 1 1 0 0 0 0\n",
    "    [0.,0.,1.,0.,1.,0.],# 0 0 1 0 1 0\n",
    "    [0.,0.,0.,1.,1.,0.],# 0 0 0 1 1 0\n",
    "    [0.,1.,0.,0.,0.,1.],# 0 1 0 0 0 1\n",
    "    [0.,0.,0.,0.,1.,1.],# 0 0 0 0 1 1\n",
    "    [0.,1.,0.,1.,0.,0.],# 0 1 0 1 0 0\n",
    "    [0.,1.,1.,0.,0.,0.] # 0 1 1 0 0 0 \n",
    "]\n",
    "\n",
    "train_2_y=[1,0,1,0,1,0,1,0]\n",
    "\n",
    "test_2_X=[\n",
    "    [1.,0.,1.,0.,0.,0.],# 1 0 1 0 0 0\n",
    "    [1.,0.,0.,1.,0.,0.],# 1 0 0 1 0 0 \n",
    "    [0.,0.,0.,1.,0.,1.],# 0 0 0 1 0 1\n",
    "    [0.,0.,1.,0.,0.,1.],# 0 0 1 0 0 1\n",
    "]\n",
    "\n",
    "test_2_y=[1,0,1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_net(train_in,test_in,train_out_list,hidden_units=4, report=False, max_epochs=20000):\n",
    "\n",
    "    #variables\n",
    "    input_units=len(train_in[0])\n",
    "    train_out=[[float(i)]for i in train_out_list]#train_1_y\n",
    "    output_units=1\n",
    "\n",
    "    # tf session preparation\n",
    "    x  = tf.placeholder(\"float\", shape=[None, input_units])# Not in original code\n",
    "    y_ = tf.placeholder(\"float\", shape=[None, output_units])# Not in original code\n",
    "\n",
    "    w1 = tf.Variable(tf.random_normal([input_units, hidden_units]))\n",
    "    b1 = tf.Variable(tf.zeros([hidden_units]))\n",
    "\n",
    "    w2 = tf.Variable(tf.random_normal([hidden_units, output_units]))\n",
    "    b2 = tf.Variable(tf.zeros([output_units]))\n",
    "\n",
    "    out1 = tf.sigmoid(tf.add(tf.matmul(x, w1), b1))# train_in\n",
    "    out2 = tf.sigmoid(tf.add(tf.matmul(out1, w2), b2))\n",
    "\n",
    "#     error = tf.subtract(y_, out2)\n",
    "#     mse = tf.reduce_mean(tf.square(error))\n",
    "    mse = tf.losses.mean_squared_error(y_, out2)\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(0.3).minimize(mse)\n",
    "\n",
    "    # Trainning session\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    err, target = 1, 0.0025\n",
    "    epoch = 0\n",
    "    mserr=[]\n",
    "\n",
    "    if report: \n",
    "        strt=time.time()\n",
    "\n",
    "    while err > target and epoch < max_epochs:\n",
    "        epoch += 1\n",
    "        err, _ = sess.run([mse, train],feed_dict={x:train_in, y_:train_out})\n",
    "        mserr.append(err)\n",
    "\n",
    "    if report: \n",
    "        converg_time=time.time()-strt\n",
    "        print(\"epoch:\", epoch, \"mse:\", err, \"time:\", converg_time)\n",
    "\n",
    "    train_prediction=out2.eval(feed_dict={x: train_in},session=sess)\n",
    "    test_prediction=out2.eval(feed_dict={x: test_in},session=sess)\n",
    "    sess.close()\n",
    "\n",
    "    return mserr,train_prediction,test_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5242 mse: 0.00249949 time: 9.175546169281006\n"
     ]
    }
   ],
   "source": [
    "err_trn, pred_trn,pred_tst=predict_net(train_2_X,test_2_X,train_2_y,\n",
    "                                           report=True, max_epochs=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94807869],\n",
       "       [ 0.06148046],\n",
       "       [ 0.93710786],\n",
       "       [ 0.0407777 ],\n",
       "       [ 0.96815866],\n",
       "       [ 0.0522774 ],\n",
       "       [ 0.96185547],\n",
       "       [ 0.05190805]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08067271],\n",
       "       [ 0.92915136],\n",
       "       [ 0.1583064 ],\n",
       "       [ 0.92925149]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iteraciones=1000\n",
    "#n_reports=20\n",
    "\n",
    "n_iter_train_1=[]\n",
    "predict_train_1=[]\n",
    "predict_test_1=[]\n",
    "\n",
    "\n",
    "n_iter_train_2=[]\n",
    "predict_train_2=[]\n",
    "predict_test_2=[]\n",
    "\n",
    "converg_times=[]\n",
    "filename=\"TF_replicas\"\n",
    "\n",
    "\n",
    "# with open(''.join([\"Results_1/\",filename,\".csv\"]), 'wb') as f:# 'wb' are the second parameter sugested values\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"exp_1_n_iter\".encode(),\n",
    "#                      \"exp_1_pred_train_1\".encode(),\n",
    "#                      \"exp_1_pred_train_2\".encode(),\n",
    "#                      \"exp_1_pred_train_3\".encode(),\n",
    "#                      \"exp_1_pred_train_4\".encode(),\n",
    "#                      \"exp_1_pred_train_5\".encode(),\n",
    "#                      \"exp_1_pred_train_6\".encode(),\n",
    "#                      \"exp_1_pred_train_7\".encode(),\n",
    "#                      \"exp_1_pred_train_8\".encode(),\n",
    "#                      \"exp_1_pred_train_9\".encode(),\n",
    "#                      \"exp_1_pred_train_10\".encode(),\n",
    "#                      \"exp_1_pred_train_11\".encode(),\n",
    "#                      \"exp_1_pred_test_1\".encode(),\n",
    "#                      \"exp_1_pred_test_2\".encode(),\n",
    "#                      \"exp_1_pred_test_3\".encode(),\n",
    "#                      \"exp_1_pred_test_4\".encode(),\n",
    "#                      \"exp_2_final_loss\".encode(),\n",
    "#                      \"exp_2_n_iter\".encode(),\n",
    "#                      \"exp_2_pred_train_1\".encode(),\n",
    "#                      \"exp_2_pred_train_2\".encode(),\n",
    "#                      \"exp_2_pred_train_3\".encode(),\n",
    "#                      \"exp_2_pred_train_4\".encode(),\n",
    "#                      \"exp_2_pred_train_5\".encode(),\n",
    "#                      \"exp_2_pred_train_6\".encode(),\n",
    "#                      \"exp_2_pred_train_7\".encode(),\n",
    "#                      \"exp_2_pred_train_8\".encode(),\n",
    "#                      \"exp_2_pred_test_1\".encode(),\n",
    "#                      \"exp_2_pred_test_2\".encode(),\n",
    "#                      \"exp_2_pred_test_3\".encode(),\n",
    "#                      \"exp_2_pred_test_4\".encode()\n",
    "#                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  0 | time:  23.199451684951782\n",
      "iter:  1 | time:  22.77290177345276\n",
      "iter:  2 | time:  21.008889198303223\n",
      "iter:  3 | time:  19.291786909103394\n",
      "iter:  4 | time:  19.98091411590576\n",
      "iter:  5 | time:  23.125616788864136\n",
      "iter:  6 | time:  24.640780210494995\n",
      "iter:  7 | time:  18.519185304641724\n",
      "iter:  8 | time:  18.588013410568237\n",
      "iter:  9 | time:  21.63394856452942\n",
      "iter:  10 | time:  18.417426824569702\n",
      "iter:  11 | time:  25.48310112953186\n",
      "iter:  12 | time:  23.2302463054657\n",
      "iter:  13 | time:  22.418742179870605\n",
      "iter:  14 | time:  21.207468509674072\n",
      "iter:  15 | time:  21.919699907302856\n",
      "iter:  16 | time:  21.367149114608765\n",
      "iter:  17 | time:  23.707412004470825\n",
      "iter:  18 | time:  20.970123052597046\n",
      "iter:  19 | time:  24.58641791343689\n",
      "iter:  20 | time:  26.38665461540222\n",
      "iter:  21 | time:  26.00441026687622\n",
      "iter:  22 | time:  20.599992513656616\n",
      "iter:  23 | time:  23.337913751602173\n",
      "iter:  24 | time:  18.91368007659912\n",
      "iter:  25 | time:  18.86335039138794\n",
      "iter:  26 | time:  25.358129739761353\n",
      "iter:  27 | time:  20.075317859649658\n",
      "iter:  28 | time:  19.786091089248657\n",
      "iter:  29 | time:  20.266555309295654\n",
      "iter:  30 | time:  23.012436389923096\n",
      "iter:  31 | time:  23.332000255584717\n",
      "iter:  32 | time:  21.592888593673706\n",
      "iter:  33 | time:  22.81558847427368\n",
      "iter:  34 | time:  23.18335747718811\n",
      "iter:  35 | time:  21.246124744415283\n",
      "iter:  36 | time:  22.399768590927124\n",
      "iter:  37 | time:  24.159526824951172\n",
      "iter:  38 | time:  20.15885829925537\n",
      "iter:  39 | time:  22.55315661430359\n",
      "iter:  40 | time:  21.08030390739441\n",
      "iter:  41 | time:  29.248741149902344\n",
      "iter:  42 | time:  28.81782102584839\n",
      "iter:  43 | time:  21.22198486328125\n",
      "iter:  44 | time:  26.6435968875885\n",
      "iter:  45 | time:  24.82856774330139\n",
      "iter:  46 | time:  26.37804627418518\n",
      "iter:  47 | time:  25.61091923713684\n",
      "iter:  48 | time:  23.675156593322754\n",
      "iter:  49 | time:  25.693293809890747\n",
      "iter:  50 | time:  23.231353998184204\n",
      "iter:  51 | time:  24.403378009796143\n",
      "iter:  52 | time:  22.643645524978638\n",
      "iter:  53 | time:  29.066410303115845\n",
      "iter:  54 | time:  22.59916377067566\n",
      "iter:  55 | time:  24.81093168258667\n",
      "iter:  56 | time:  24.953972339630127\n",
      "iter:  57 | time:  25.07172918319702\n",
      "iter:  58 | time:  27.59951949119568\n",
      "iter:  59 | time:  24.52912974357605\n",
      "iter:  60 | time:  28.554365396499634\n",
      "iter:  61 | time:  23.260363817214966\n",
      "iter:  62 | time:  26.81479525566101\n",
      "iter:  63 | time:  26.77193522453308\n",
      "iter:  64 | time:  32.30737590789795\n",
      "iter:  65 | time:  24.783085107803345\n",
      "iter:  66 | time:  25.965964555740356\n",
      "iter:  67 | time:  26.75842595100403\n",
      "iter:  68 | time:  28.462895154953003\n",
      "iter:  69 | time:  29.7949001789093\n",
      "iter:  70 | time:  24.50926446914673\n",
      "iter:  71 | time:  30.26729702949524\n",
      "iter:  72 | time:  27.272669076919556\n",
      "iter:  73 | time:  32.13712167739868\n",
      "iter:  74 | time:  26.84807586669922\n",
      "iter:  75 | time:  28.579723596572876\n",
      "iter:  76 | time:  27.026735067367554\n",
      "iter:  77 | time:  29.66931986808777\n",
      "iter:  78 | time:  27.53214693069458\n",
      "iter:  79 | time:  35.56222176551819\n",
      "iter:  80 | time:  26.620707511901855\n",
      "iter:  81 | time:  26.615206956863403\n",
      "iter:  82 | time:  26.99044704437256\n",
      "iter:  83 | time:  28.202574014663696\n",
      "iter:  84 | time:  27.878761529922485\n",
      "iter:  85 | time:  28.27713131904602\n",
      "iter:  86 | time:  28.914395093917847\n",
      "iter:  87 | time:  32.663126945495605\n",
      "iter:  88 | time:  30.44238829612732\n",
      "iter:  89 | time:  28.024335145950317\n",
      "iter:  90 | time:  30.086509943008423\n",
      "iter:  91 | time:  30.7905216217041\n",
      "iter:  92 | time:  31.650071382522583\n",
      "iter:  93 | time:  27.635003328323364\n",
      "iter:  94 | time:  30.92736053466797\n",
      "iter:  95 | time:  34.07346796989441\n",
      "iter:  96 | time:  29.79554057121277\n",
      "iter:  97 | time:  30.13403630256653\n",
      "iter:  98 | time:  30.176036834716797\n",
      "iter:  99 | time:  31.244653701782227\n",
      "iter:  100 | time:  31.742911100387573\n",
      "iter:  101 | time:  33.96478748321533\n",
      "iter:  102 | time:  29.739177465438843\n"
     ]
    }
   ],
   "source": [
    "for corrida in range(iteraciones):\n",
    "    strt_time=time.time()\n",
    "    \n",
    "#     if __name__ == '__main__':\n",
    "#         pool = Pool()\n",
    "#         err_list_1, pred_train_1,pred_test_1=predict_net(train_1_X,test_1_X,train_1_y)\n",
    "#         err_list_2, pred_train_2,pred_test_2=predict_net(train_2_X,test_2_X,train_2_y)    \n",
    "#         pool.close() \n",
    "#         pool.join()\n",
    "    \n",
    "    err_list_1, pred_train_1,pred_test_1=predict_net(train_1_X,test_1_X,train_1_y)\n",
    "    err_list_2, pred_train_2,pred_test_2=predict_net(train_2_X,test_2_X,train_2_y)    \n",
    "\n",
    "    iter_vals=[item for sublist in [[len(err_list_1)],\n",
    "                                    [float(p) for p in pred_train_1],\n",
    "                                    [float(p) for p in pred_test_1],\n",
    "                                    [err_list_2[-1]],\n",
    "                                    [len(err_list_2)],\n",
    "                                    [float(p) for p in pred_train_2],\n",
    "                                    [float(p) for p in pred_test_2],\n",
    "                                   ] for item in sublist]\n",
    "\n",
    "\n",
    "#     converg_times.append(end_time-strt_time)\n",
    "\n",
    "    with open(''.join([\"Results_1/\",filename,\".csv\"]), 'a') as f:# 'wb' are the second parameter sugested values\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(iter_vals)\n",
    "    \n",
    "    end_time=time.time()\n",
    "    print(\"iter: \", str(corrida), \"| time: \", str(end_time-strt_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_csv(\"Results_1/TF_replicas.csv\", \n",
    "                header=None, \n",
    "                names=([\"exp_1_n_epocs\",\n",
    "                        \"XY_1\",\n",
    "                        \"YZ_1\",\n",
    "                        \"XZ_1\",\n",
    "                        \"A1B1_1\",\n",
    "                        \"A1B2_1\",\n",
    "                        \"B1C1_1\",\n",
    "                        \"B1C2_1\",\n",
    "                        \"A2B2_1\",\n",
    "                        \"A2B1_1\",\n",
    "                        \"B2C2_1\",\n",
    "                        \"B2C1_1\",\n",
    "                        \"A1C1_1\",\n",
    "                        \"A1C2_1\",\n",
    "                        \"A2C2_1\",\n",
    "                        \"A2C1_1\",\n",
    "                        \"exp_2_final_loss\",\n",
    "                        \"exp_2_n_epocs\",\n",
    "                        \"A1B1_2\",\n",
    "                        \"A1B2_2\",\n",
    "                        \"B1C1_2\",\n",
    "                        \"B1C2_2\",\n",
    "                        \"A2B2_2\",\n",
    "                        \"A2B1_2\",\n",
    "                        \"B2C2_2\",\n",
    "                        \"B2C1_2\",\n",
    "                        \"A1C1_2\",\n",
    "                        \"A1C2_2\",\n",
    "                        \"A2C2_2\",\n",
    "                        \"A2C1_2\",\n",
    "                       ]))# , sep=\";\" # para bases en español #_hid_4_1\n",
    "#dat=pd.read_csv(\"Results_1/test_hid_4_1.csv\")# , sep=\";\" # para bases en español #_hid_4_1\n",
    "print(len(dat))\n",
    "print(list(dat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dat[\"exp_1_n_epocs\"])\n",
    "#dat[\"exp_1_n_epocs\"].plot.density(figsize=(12,8),alpha=0.6)\n",
    "dat[\"exp_1_n_epocs\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.plot.scatter(\n",
    "    x='exp_2_n_epocs',\n",
    "    y='exp_2_final_loss',\n",
    "    ylim=(dat[\"exp_2_final_loss\"].min(),dat[\"exp_2_final_loss\"].max()),\n",
    "    xlim=(dat[\"exp_2_n_epocs\"].min(),dat[\"exp_2_n_epocs\"].max()),\n",
    "    figsize=(12,8),\n",
    "    alpha=0.4\n",
    ")\n",
    "#dat['exp_1_loss'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[\"exp_2_final_loss\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dat[\"exp_2_n_epocs\"])\n",
    "#dat[\"exp_2_final_loss\"].plot.density(figsize=(12,8),alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,1:12].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,1:12].plot(kind=\"box\", figsize=(16,8))#, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,1:12].plot(kind=\"density\", figsize=(16,8))#, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,12:16].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,12:16].plot(kind=\"box\", figsize=(16,8))#, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,12:16].plot.density(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,18:26].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,18:26].plot(kind=\"box\", figsize=(16,8))#, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,18:26].plot(kind=\"density\", figsize=(16,8))#, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,26:30].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,26:30].plot(kind=\"box\", figsize=(16,8))#, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.iloc[:,26:30].plot(kind=\"density\", figsize=(16,8))#, alpha=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
