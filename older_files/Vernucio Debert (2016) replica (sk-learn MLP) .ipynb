{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Simulation of Equivalence Class Formation Using the go/no-go Procedure with Compound Stimuli\n",
    "\n",
    "### Abstract\n",
    "Research about equivalence has commonly utilized human participants as experimental subjects. More recently, computational models have been capable of reproducing performances observed in experiments with humans. The computational model often utilized is called RELNET, and it simulates training and testing trials of conditional relations using the matching-to-sample procedure (MTS). The differentiation between sample stimulus and comparison stimuli, indispensable in MTS, implies operational difficulties for simulations. For this reason, new studies seek to utilize alternative procedures to MTS, which do not differentiate the functions of the antecedent stimuli. This work evaluated the possibility of developing a new computational model to simulate equivalence class formation using the go/no-go procedure with compound stimuli. In Experiment 1, artificial neural networks were utilized to simulate training of the AB and BC relations as well as the testing of the AC relation. The results showed that four out of six runs demonstrated equivalence class formation. Experiment 2 evaluated whether the additional class training performed in Experiment 1, which was analogous to the simulation of pre-experimental experience of human participants, would be essential for simulating the establishment of equivalence classes. It was found that it was not possible to simulate equivalence class formation without the additional class training. Altogether, the experiments show that it is possible to simulate equivalence class formation using the go/no-go procedure with compound stimuli and that it is necessary to conduct additional class training. The model developed is, therefore, an alternative to RELNET for the study of equivalence relations using computational simulations.\n",
    "\n",
    "[article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4960284/pdf/40732_2016_Article_184.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import time\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_X=np.array([\n",
    "    [0.,0.,0.,1.,0.,1.,0.,0.,0.],# 0 0 0 1 0 1 0 0 0 \n",
    "    [0.,1.,0.,0.,0.,1.,0.,0.,0.],# 0 1 0 0 0 1 0 0 0\n",
    "    [0.,1.,0.,1.,0.,0.,0.,0.,0.],# 0 1 0 1 0 0 0 0 0\n",
    "    [1.,0.,0.,0.,0.,0.,0.,1.,0.],# 1 0 0 0 0 0 0 1 0  \n",
    "    [1.,0.,1.,0.,0.,0.,0.,0.,0.],# 1 0 1 0 0 0 0 0 0 \n",
    "    [0.,0.,0.,0.,1.,0.,0.,1.,0.],# 0 0 0 0 1 0 0 1 0 \n",
    "    [0.,0.,0.,0.,0.,0.,1.,1.,0.],# 0 0 0 0 0 0 1 1 0 \n",
    "    [0.,0.,1.,0.,0.,0.,0.,0.,1.],# 0 0 1 0 0 0 0 0 1\n",
    "    [0.,0.,0.,0.,0.,0.,0.,1.,1.],# 0 0 0 0 0 0 0 1 1 \n",
    "    [0.,0.,1.,0.,0.,0.,1.,0.,0.],# 0 0 1 0 0 0 1 0 0\n",
    "    [0.,0.,1.,0.,1.,0.,0.,0.,0.] # 0 0 1 0 1 0 0 0 0 \n",
    "])\n",
    "train_1_y=np.array([1.,1.,1.,1.,0.,1.,0.,1.,0.,1.,0.])\n",
    "\n",
    "test_1_X=np.array([\n",
    "    [1.,0.,0.,0.,1.,0.,0.,0.,0.],\n",
    "    [1.,0.,0.,0.,0.,0.,1.,0.,0.],\n",
    "    [0.,0.,0.,0.,0.,0.,1.,0.,1.],\n",
    "    [0.,0.,0.,0.,1.,0.,0.,0.,1.]\n",
    "])\n",
    "\n",
    "test_1_y=np.array([1.,0.,1.,0.])\n",
    "\n",
    "\n",
    "train_2_X=np.array([\n",
    "    [1.,0.,0.,0.,1.,0.],# 1 0 0 0 1 0\n",
    "    [1.,1.,0.,0.,0.,0.],# 1 1 0 0 0 0\n",
    "    [1.,1.,0.,0.,0.,0.],# 0 0 1 0 1 0\n",
    "    [0.,0.,0.,1.,1.,0.],# 0 0 0 1 1 0\n",
    "    [0.,1.,0.,0.,0.,1.],# 0 1 0 0 0 1\n",
    "    [0.,0.,0.,0.,1.,1.],# 0 0 0 0 1 1\n",
    "    [0.,1.,0.,1.,0.,0.],# 0 1 0 1 0 0\n",
    "    [0.,1.,1.,0.,0.,0.] # 0 1 1 0 0 0 \n",
    "])\n",
    "train_2_y=np.array([1.,0.,1.,0.,1.,0.,1.,0.])\n",
    "\n",
    "test_2_X=np.array([\n",
    "    [1.,0.,1.,0.,0.,0.],# 1 0 1 0 0 0\n",
    "    [1.,0.,0.,1.,0.,0.],# 1 0 0 1 0 0 \n",
    "    [0.,0.,0.,1.,0.,1.],# 0 0 0 1 0 1\n",
    "    [0.,0.,1.,0.,0.,1.],# 0 0 1 0 0 1\n",
    "])\n",
    "\n",
    "test_2_y=np.array([1.,0.,1.,0.])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(#MLPClassifier #MLPRegressor\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate='adaptive',# experiment sets constant to 0.3 # I rather prefer adaptive (the other option: invscaling)\n",
    "    learning_rate_init=0.3,\n",
    "    momentum=0,\n",
    "    max_iter=200000,\n",
    "    validation_fraction=0,\n",
    "    verbose=True,\n",
    "    tol=1e-10,\n",
    "    hidden_layer_sizes=(4)\n",
    ")\n",
    "mlp.fit(train_1_X,train_1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train  predict\n",
       "0     1.0      1.0\n",
       "1     1.0      1.0\n",
       "2     1.0      1.0\n",
       "3     1.0      1.0\n",
       "4     0.0      0.0\n",
       "5     1.0      1.0\n",
       "6     0.0      0.0\n",
       "7     1.0      1.0\n",
       "8     0.0      0.0\n",
       "9     1.0      1.0\n",
       "10    0.0      0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack([train_1_y,mlp.predict(train_1_X).round(2)]), columns=(\"train\",\"predict\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test  predict\n",
       "0   1.0      1.0\n",
       "1   0.0      0.0\n",
       "2   1.0      1.0\n",
       "3   0.0      0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack([test_1_y,mlp.predict(test_1_X).round(2)]), columns=(\"test\",\"predict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2 = MLPClassifier(#MLPClassifier #MLPRegressor\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate='adaptive',# experiment sets constant to 0.3 # I rather prefer adaptive (the other option: invscaling)\n",
    "    learning_rate_init=0.3,\n",
    "    momentum=0,\n",
    "    max_iter=200000,\n",
    "    validation_fraction=0,\n",
    "    verbose=True,\n",
    "    tol=1e-12,\n",
    "    hidden_layer_sizes=(4)\n",
    ")\n",
    "mlp_2.fit(train_2_X,train_2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  predict\n",
       "0    1.0      1.0\n",
       "1    0.0      1.0\n",
       "2    1.0      1.0\n",
       "3    0.0      0.0\n",
       "4    1.0      1.0\n",
       "5    0.0      0.0\n",
       "6    1.0      1.0\n",
       "7    0.0      0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack([train_2_y,mlp_2.predict(train_2_X).round(2)]), columns=(\"train\",\"predict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test  predict\n",
       "0   1.0      0.0\n",
       "1   0.0      1.0\n",
       "2   1.0      1.0\n",
       "3   0.0      0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack([test_2_y,mlp_2.predict(test_2_X).round(2)]), columns=(\"test\",\"predict\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replica Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(13*60)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteraciones=100000\n",
    "#n_reports=20\n",
    "\n",
    "loss_train_1=[]\n",
    "n_iter_train_1=[]\n",
    "predict_train_1=[]\n",
    "predict_test_1=[]\n",
    "\n",
    "loss_train_2=[]\n",
    "n_iter_train_2=[]\n",
    "predict_train_2=[]\n",
    "predict_test_2=[]\n",
    "\n",
    "converg_times=[]\n",
    "\n",
    "filename=\"test\"\n",
    "# with open(''.join([\"Results_1/\",filename,\".csv\"]), 'wb') as f:# 'wb' are the second parameter sugested values\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\n",
    "#         \"exp_1_loss\",\n",
    "#         \"exp_1_n_iter\",\n",
    "#         \"exp_1_pred_train_1\",\n",
    "#         \"exp_1_pred_train_2\",\n",
    "#         \"exp_1_pred_train_3\",\n",
    "#         \"exp_1_pred_train_4\",\n",
    "#         \"exp_1_pred_train_5\",\n",
    "#         \"exp_1_pred_train_6\",\n",
    "#         \"exp_1_pred_train_7\",\n",
    "#         \"exp_1_pred_train_8\",\n",
    "#         \"exp_1_pred_train_9\",\n",
    "#         \"exp_1_pred_train_10\",\n",
    "#         \"exp_1_pred_train_11\",\n",
    "#         \"exp_1_pred_test_1\",\n",
    "#         \"exp_1_pred_test_2\",\n",
    "#         \"exp_1_pred_test_3\",\n",
    "#         \"exp_1_pred_test_4\",\n",
    "#         \"exp_2_loss\",\n",
    "#         \"exp_2_n_iter\",\n",
    "#         \"exp_2_pred_train_1\",\n",
    "#         \"exp_2_pred_train_2\",\n",
    "#         \"exp_2_pred_train_3\",\n",
    "#         \"exp_2_pred_train_4\",\n",
    "#         \"exp_2_pred_train_5\",\n",
    "#         \"exp_2_pred_train_6\",\n",
    "#         \"exp_2_pred_train_7\",\n",
    "#         \"exp_2_pred_train_8\",\n",
    "#         \"exp_2_pred_test_1\",\n",
    "#         \"exp_2_pred_test_2\",\n",
    "#         \"exp_2_pred_test_3\",\n",
    "#         \"exp_2_pred_test_4\",\n",
    "#     ])\n",
    "        \n",
    "        \n",
    "for corrida in range(iteraciones):\n",
    "    strt_time=time.time()\n",
    "    mlp_1 = MLPRegressor(#MLPClassifier #MLPRegressor\n",
    "        activation='logistic',\n",
    "        solver='sgd',\n",
    "        learning_rate='adaptive',# experiment sets constant to 0.3 # I rather prefer adaptive (the other option: invscaling)\n",
    "        learning_rate_init=1,\n",
    "        momentum=0,\n",
    "        max_iter=200000,\n",
    "        validation_fraction=0,\n",
    "        #verbose=True,\n",
    "        tol=1e-10,\n",
    "        hidden_layer_sizes=(4)\n",
    "    )\n",
    "    \n",
    "    mlp_1.fit(train_1_X,train_1_y)\n",
    "#     predict_train_1.append(mlp_1.predict(train_1_X))\n",
    "#     predict_test_1.append (mlp_1.predict(test_1_X))\n",
    "#     n_iter_train_1.append(mlp_1.n_iter_)\n",
    "#     loss_train_1.append(mlp_1.loss_)\n",
    "#     iter_vals_1=[item for sublist in [[mlp_1.loss_],\n",
    "#                           [mlp_1.n_iter_],\n",
    "#                           list(mlp_1.predict(train_1_X)),\n",
    "#                           list(mlp_1.predict(test_1_X))\n",
    "#                          ] for item in sublist]\n",
    "\n",
    "    mlp_2 = MLPRegressor(#MLPClassifier #MLPRegressor\n",
    "        activation='logistic',\n",
    "        solver='sgd',\n",
    "        learning_rate='adaptive',# experiment sets constant to 0.3 # I rather prefer adaptive (the other option: invscaling)\n",
    "        learning_rate_init=1,\n",
    "        momentum=0,\n",
    "        max_iter=200000,\n",
    "        validation_fraction=0,\n",
    "        #verbose=True,\n",
    "        tol=1e-10,\n",
    "        hidden_layer_sizes=(4)\n",
    "    )\n",
    "    \n",
    "    mlp_2.fit(train_2_X,train_2_y)\n",
    "#     predict_train_2.append(mlp_2.predict(train_2_X))\n",
    "#     predict_test_2.append (mlp_2.predict(test_2_X))\n",
    "#     n_iter_train_2.append(mlp_2.n_iter_)\n",
    "#     loss_train_2.append(mlp_2.loss_)\n",
    "#     iter_vals_2=[item for sublist in [[mlp_2.loss_],\n",
    "#                           [mlp_2.n_iter_],\n",
    "#                           list(mlp_2.predict(train_2_X)),\n",
    "#                           list(mlp_2.predict(test_2_X))\n",
    "#                          ] for item in sublist]\n",
    "\n",
    "    iter_vals=[item for sublist in [[mlp_1.loss_],\n",
    "                                    [mlp_1.n_iter_],\n",
    "                                    list(mlp_1.predict(train_1_X)),\n",
    "                                    list(mlp_1.predict(test_1_X)),\n",
    "                                    [mlp_2.loss_],\n",
    "                                    [mlp_2.n_iter_],\n",
    "                                    list(mlp_2.predict(train_2_X)),\n",
    "                                    list(mlp_2.predict(test_2_X))\n",
    "                                   ] for item in sublist]\n",
    "\n",
    "    end_time=time.time()\n",
    "#     converg_times.append(end_time-strt_time)\n",
    "\n",
    "    with open(''.join([\"Results_1/\",filename,\".csv\"]), 'a') as f:# 'wb' are the second parameter sugested values\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(iter_vals)\n",
    "    print(\"iter: \", str(corrida), \"| time: \", str(end_time-strt_time))\n",
    "\n",
    "\n",
    "#     if i %(iteraciones/n_reports)==0:\n",
    "#         np.savetxt(\"Results_1/PSO.csv\",np.array(best_nCorrds_mIters))\n",
    "#         with open(\"Results_1/PSO_best_part.csv\", 'wb') as f:\n",
    "#             writer = csv.writer(f)\n",
    "#             [writer.writerow([best_bit])for best_bit in best_nCorrds_mIters_bit]\n",
    "\n",
    "# np.savetxt(\"Results_1/PSO.csv\",np.array(best_nCorrds_mIters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.read_csv(\"Results_1/test.csv\")# , sep=\";\" # para bases en espa√±ol\n",
    "list(dat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFJCAYAAAC2OXUDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwBgCUobAABL/H/QzG8rtAdNtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf4ac796d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train_1, \"o\")\n",
    "plt.plot(loss_train_2, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exp_1_loss',\n",
       " 'exp_1_n_iter',\n",
       " 'exp_1_pred_train_1',\n",
       " 'exp_1_pred_train_2',\n",
       " 'exp_1_pred_train_3',\n",
       " 'exp_1_pred_train_4',\n",
       " 'exp_1_pred_train_5',\n",
       " 'exp_1_pred_train_6',\n",
       " 'exp_1_pred_train_7',\n",
       " 'exp_1_pred_train_8',\n",
       " 'exp_1_pred_train_9',\n",
       " 'exp_1_pred_train_10',\n",
       " 'exp_1_pred_train_11',\n",
       " 'exp_1_pred_test_1',\n",
       " 'exp_1_pred_test_2',\n",
       " 'exp_1_pred_test_3',\n",
       " 'exp_1_pred_test_4',\n",
       " 'exp_2_loss',\n",
       " 'exp_2_n_iter',\n",
       " 'exp_2_pred_train_1',\n",
       " 'exp_2_pred_train_2',\n",
       " 'exp_2_pred_train_3',\n",
       " 'exp_2_pred_train_4',\n",
       " 'exp_2_pred_train_5',\n",
       " 'exp_2_pred_train_6',\n",
       " 'exp_2_pred_train_7',\n",
       " 'exp_2_pred_train_8',\n",
       " 'exp_2_pred_test_1',\n",
       " 'exp_2_pred_test_2',\n",
       " 'exp_2_pred_test_3',\n",
       " 'exp_2_pred_test_4']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=pd.read_csv(\"Results_1/test_b.csv\")\n",
    "list(dat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.12\n",
      "0.024\n",
      "0.0048\n",
      "0.00096\n",
      "0.000192\n",
      "3.84e-05\n",
      "7.68e-06\n",
      "1.536e-06\n",
      "3.072e-07\n"
     ]
    }
   ],
   "source": [
    "n=3.\n",
    "\n",
    "for i in xrange(10):\n",
    "    n=n/5\n",
    "    print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(predict_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(predict_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasifiers Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\", \n",
    "    \"Linear SVM\", \n",
    "    \"RBF SVM\", \n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\", \n",
    "    \"Random Forest\", \n",
    "    \"Neural Net\", \n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\", \n",
    "    \"QDA\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, tol=1e-12, learning_rate='adaptive',hidden_layer_sizes=(4)),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_scores_train=[]\n",
    "avg_scores_test=[]\n",
    "#train_clasif=[]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clasif=clf.fit(train_1_X, train_1_y)\n",
    "    #train_clasif.append(clasif)\n",
    "    scr=average_precision_score(train_1_y,clasif.predict(train_1_X))\n",
    "    avg_scores_train.append(scr)\n",
    "    scr_test=average_precision_score(test_1_y,clasif.predict(test_1_X))\n",
    "    avg_scores_test.append(scr_test)\n",
    "\n",
    "    print(name,scr,scr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_scores_train_2=[]\n",
    "avg_scores_test_2=[]\n",
    "#train_clasif=[]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clasif=clf.fit(train_2_X, train_2_y)\n",
    "    #train_clasif.append(clasif)\n",
    "    scr=average_precision_score(train_2_y,clasif.predict(train_2_X))\n",
    "    avg_scores_train.append(scr)\n",
    "    scr_test=average_precision_score(test_2_y,clasif.predict(test_2_X))\n",
    "    avg_scores_test.append(scr_test)\n",
    "\n",
    "    print(name,scr,scr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
